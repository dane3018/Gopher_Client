"""
Class to store all fields associated with the assignment specs
and methods to update these values
"""
from util_functions import send_request, read_response, get_resources


class GopherCrawler:
    def __init__(self, hostname, portno):
        self.hostname = hostname
        self.portno = portno
        self.num_directories = 0
        self.text_files = []
        self.binary_files = []
        self.smallest_text_file_contents = None
        self.largest_text_file_size = 0
        self.smallest_binary_file_size = float('inf')
        self.largest_binary_file_size = 0
        self.num_invalid_references = 0
        self.external_servers = {}  # {server_address: up_status}
        self.error_references = []

        self.visited_dirs = [] # keep track of which directories have been visited 

    # Other methods and attributes...

    def print_stats(self):
        """
        Note Generated by ChatGPT. Used to print all items of the class to stdout 
        """
        print("Text files found:")
        print("\n".join(self.text_files))
        
        print("\nBinary files found:")
        print("\n".join(self.binary_files))
        
        print("\nSmallest text file contents:")
        print(self.smallest_text_file_contents)
        
        print("\nLargest text file size:")
        print(self.largest_text_file_size)
        
        print("\nSmallest binary file size:")
        print(self.smallest_binary_file_size)
        
        print("\nLargest binary file size:")
        print(self.largest_binary_file_size)
        
        print("\nNumber of invalid references:")
        print(self.num_invalid_references)
        
        print("\nExternal servers:")
        for server, status in self.external_servers.items():
            print(f"{server}: {'up' if status else 'down'}")
        
        print("\nError references:")
        print("\n".join(self.error_references))


    
   
    
    # don't wanna follow a direcotry unless it is a new request 
    def crawl_resource(self, res):
        # Recursive Base cases
        res_type = res['type']
        selector = res['selector']
        sock = send_request(selector, self.hostname, self.portno)
        is_bin = res_type == '9'
        response = read_response(sock, is_bin)
        # txt file 
        if res_type == '0':
            self.text_files.append(selector)
            # Update smallest text file 
            if not self.smallest_text_file_contents or len(response) < len(self.smallest_text_file_contents):
                self.smallest_text_file_contents = response
            # Update largest text file 
            if len(response) > self.largest_text_file_size:
                self.largest_text_file_size = len(response)


        # directory case 
        elif res_type == '1':
            # already visited this directory
            if selector in self.visited_dirs:
                return
            self.visited_dirs.append(selector)
            response_resources = get_resources(response)
            if not response_resources or response_resources == []:
                print('Empty dir') #TODO remove
                return
            # recursively crawl every resource in directory
            for resource in response_resources:
                self.crawl_resource(resource)
        
        else: print("different type of resource")
            



